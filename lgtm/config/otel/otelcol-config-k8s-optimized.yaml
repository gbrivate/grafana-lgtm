receivers:
  filelog:
    include:
      - /var/log/pods/*/*/*.log
    exclude:
      - /var/log/pods/*/otc-container/*.log

    include_file_path: true
    start_at: beginning
    max_concurrent_files: 1000
    poll_interval: 500ms

    operators:
      # 1. Extrai namespace/pod/container da estrutura K8s
      - type: regex_parser
        parse_from: attributes["log.file.path"]
        regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9-]+)\/(?P<container_name>[^\/]+)\/(?P<restart_count>\d+)\.log$'

      # 2. Parse CRI log format (stdout/stderr + timestamp + msg)
      - type: regex_parser
        regex: '^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
        timestamp:
          parse_from: attributes.time
          layout: '%Y-%m-%dT%H:%M:%S.%LZ'

      # 3. Se o conteúdo for JSON → parse de JSON estruturado
      - type: json_parser
        parse_from: attributes.log
        if: 'attributes.log != nil'

      # 4. Normaliza container_name removendo sufixos de runtime
      - type: regex_parser
        parse_from: attributes.container_name
        regex: '^(?P<container_name>[^._]+)'
        if: 'attributes.container_name != nil'

      # 5. Mapeia CRI timestamp para body.time se existir
      - type: move
        from: attributes.time
        to: attributes["cri.time"]
        if: 'attributes.time != nil'

      # 6. Promove namespace/pod/container para resource attributes
      - type: move
        from: attributes.namespace
        to: resource["k8s.namespace.name"]
        if: 'attributes.namespace != nil'

      - type: move
        from: attributes.pod_name
        to: resource["k8s.pod.name"]
        if: 'attributes.pod_name != nil'

      - type: move
        from: attributes.container_name
        to: resource["k8s.container.name"]
        if: 'attributes.container_name != nil'

      - type: move
        from: attributes.uid
        to: resource["k8s.pod.uid"]
        if: 'attributes.uid != nil'

      # 7. Remove ruído
      - type: remove
        field: attributes.logtag
        if: 'attributes.logtag != nil'

      - type: remove
        field: attributes["log.file.path"]

  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  kubeletstats:
    collection_interval: 10s
    auth_type: serviceAccount
    endpoint: https://${NODE_NAME}:10250
    insecure_skip_verify: true
    metric_groups: [node, pod, container, volume]

  prometheus/kubelet:
    config:
      scrape_configs:
        - job_name: "kubelet"
          scheme: https
          scrape_interval: 10s
          tls_config:
            insecure_skip_verify: true
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          static_configs:
            - targets: ["${NODE_NAME}:10250"]

  prometheus/ksm:
    config:
      scrape_configs:
        - job_name: "kube-state-metrics"
          scrape_interval: 15s
          static_configs:
            - targets: ["ksm-kube-state-metrics.kube-system.svc.cluster.local:8080"]

  prometheus/self:
    config:
      scrape_configs:
        - job_name: otel-collector
          static_configs:
            - targets: ["127.0.0.1:8888"]

  hostmetrics:
    scrapers:
      cpu: {}
      memory: {}
      filesystem: {}
      network: {}
      load: {}
      processes: {}
      paging: {}


processors:
  memory_limiter:
    check_interval: 1s
    limit_mib: 2048
    spike_limit_mib: 512

  batch:
    send_batch_size: 5000
    timeout: 5s

  k8sattributes:
    auth_type: serviceAccount
    passthrough: false
    extract:
      metadata:
        - k8s.namespace.name
        - k8s.pod.name
        - k8s.pod.uid
        - k8s.node.name
        - k8s.deployment.name
        - k8s.replicaset.name
      labels:
        - key: app
        - key: app.kubernetes.io/name
    pod_association:
      - sources:
          - from: resource_attribute
            name: k8s.pod.ip
      - sources:
          - from: resource_attribute
            name: k8s.pod.uid
      - sources:
          - from: connection

  transform:
    metric_statements:
      - context: datapoint
        statements:
          - set(datapoint.attributes["namespace"], resource.attributes["k8s.namespace.name"])
          - set(datapoint.attributes["pod"], resource.attributes["k8s.pod.name"])
          - set(datapoint.attributes["deployment"], resource.attributes["k8s.deployment.name"])
          - set(datapoint.attributes["instance"], resource.attributes["k8s.pod.name"])
          - set(datapoint.attributes["deployment"], resource.attributes["k8s.replicaset.name"]) where datapoint.attributes["deployment"] == nil
          - set(datapoint.attributes["deployment"], resource.attributes["k8s.daemonset.name"]) where datapoint.attributes["deployment"] == nil
          - replace_pattern(datapoint.attributes["deployment"], "-[a-f0-9]+$", "")
          - set(datapoint.attributes["phase"], resource.attributes["k8s.pod.phase"])

    log_statements:
      - context: log
        statements:
          # Normaliza severidade
          - set(severity_text, attributes.level) where attributes.level != nil
          - set(severity_text, attributes.severity) where attributes.severity != nil
          - set(severity_number, SEVERITY_NUMBER_INFO) where severity_text == "info"
          - set(severity_number, SEVERITY_NUMBER_WARN) where severity_text in ["warn", "warning"]
          - set(severity_number, SEVERITY_NUMBER_ERROR) where severity_text == "error"
          - set(severity_number, SEVERITY_NUMBER_DEBUG) where severity_text == "debug"

          # Promove JSON field "msg" se existir
          - set(body, attributes.msg) where attributes.msg != nil

  attributes/cleanup:
    actions:
      - key: log.file.path
        action: delete
      - key: logtag
        action: delete


exporters:
  otlphttp/logs:
    endpoint: http://127.0.0.1:3100/otlp
    tls:
      insecure: true

  otlphttp/metrics:
    endpoint: http://127.0.0.1:9090/api/v1/otlp
    tls:
      insecure: true

  otlphttp/traces:
    endpoint: http://127.0.0.1:4418
    tls:
      insecure: true

  prometheusremotewrite:
    endpoint: http://127.0.0.1:9090/api/v1/write
    tls:
      insecure: true

  otlp/profiles:
    endpoint: http://127.0.0.1:4040
    tls:
      insecure: true


extensions:
  health_check:
    endpoint: 0.0.0.0:13133
  pprof:
  zpages:
    endpoint: 0.0.0.0:55679


service:
  extensions: [health_check]
  pipelines:
    logs:
      receivers: [filelog, otlp]
      processors: [memory_limiter, k8sattributes, attributes/cleanup, batch]
      exporters: [otlphttp/logs]

    metrics:
      receivers: [otlp, kubeletstats, prometheus/kubelet, prometheus/ksm, prometheus/self]
      processors: [memory_limiter, k8sattributes, transform, batch]
      exporters: [otlphttp/metrics, prometheusremotewrite]

    traces:
      receivers: [otlp]
      processors: [memory_limiter, k8sattributes, batch]
      exporters: [otlphttp/traces]

    profiles:
      receivers: [otlp]
      processors: []
      exporters: [otlp/profiles]
