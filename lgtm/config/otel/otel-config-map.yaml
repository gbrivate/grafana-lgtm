apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: otelcol-config
  namespace: monitoring
data:
  otelcol-config.yaml: |
    receivers:
      filelog:
        include:
          - /var/log/pods/*/*/*.log
          - /var/lib/postgresql/data/log/*.log # postgresql logs
        exclude: [ "/var/log/pods/*/otc-container/*.log" ]
        include_file_path: true
        start_at: beginning
        max_concurrent_files: 200
        poll_interval: 4s
        operators:
          - id: container-parser
            type: container

      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
            cors:
              allowed_origins:
                - http://*
              allowed_headers:
              - "*"

      # kubeletstats: métricas de CPU/memória/rede por Pod e Node
      kubeletstats:
        collection_interval: 5s
        auth_type: serviceAccount
        endpoint: https://${NODE_NAME}:10250
        insecure_skip_verify: true
        metric_groups: [node, pod, container, volume]
        
      # MÉTRICAS DO CLUSTER (node allocatable, pod count, namespace stats etc)
      k8s_cluster:
        collection_interval: 5s

      # Scrape do OTel Collector (self-metrics)
      prometheus/self:
        config:
          scrape_configs:
            - job_name: "otel-collector"
              scrape_interval: 5s
              static_configs:
                - targets: ["127.0.0.1:8888"]

      # Scrape do kube-state-metrics
      prometheus/ksm:
        config:
          scrape_configs:
            - job_name: "kube-state-metrics"
              scrape_interval: 5s
              static_configs:
                - targets: ["ksm-kube-state-metrics.kube-system.svc.cluster.local:8080"]
                  
      prometheus/ingress:
        config:
          scrape_configs:
            - job_name: "ingress-nginx"
              scrape_interval: 5s
              static_configs:
                - targets: ["ingress-nginx-controller.ingress-nginx.svc.cluster.local:10254"]

      # -------------------------------
      # PostgreSQL Metrics Receiver
      # -------------------------------
      postgresql:
        endpoint: postgres-service.datastore.svc.cluster.local:5432 # using k8s change for postgres-service.{namespace}.svc.cluster.local:5432
        username: myuser
        password: mypassword
        databases:
          - mydb
        collection_interval: 5s
        tls:
          insecure: true

    extensions:
      health_check:
        endpoint: 0.0.0.0:13133
      pprof:
      zpages:
        endpoint: 0.0.0.0:55679

    processors:
      memory_limiter:
        check_interval: 1s
        limit_mib: 2024
        spike_limit_mib: 500

      # reduced batch size to lower window-risk for duplicated timestamps
      batch:
        send_batch_size: 1024
        timeout: 5s

      k8sattributes:
        auth_type: serviceAccount
        passthrough: false
        extract:
          metadata:
            - k8s.namespace.name
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.node.name
            - k8s.deployment.name
            - k8s.replicaset.name
            - k8s.daemonset.name
            - k8s.statefulset.name
          labels:
            - key: app
            - key: app.kubernetes.io/name
        pod_association:
          - sources:
              - from: resource_attribute
                name: k8s.pod.ip
          - sources:
              - from: resource_attribute
                name: k8s.pod.uid
          - sources:
              - from: connection

      resourcedetection:
        detectors: [ env, system, docker, kubernetes ]

      transform:
        metric_statements:
          - context: datapoint
            statements:
              - set(datapoint.attributes["namespace"], resource.attributes["k8s.namespace.name"])
              - set(datapoint.attributes["pod"], resource.attributes["k8s.pod.name"])
              - set(datapoint.attributes["deployment"], resource.attributes["k8s.deployment.name"])
              - set(datapoint.attributes["instance"], resource.attributes["k8s.pod.name"])
              - set(datapoint.attributes["deployment"], resource.attributes["k8s.replicaset.name"]) where datapoint.attributes["deployment"] == nil
              - set(datapoint.attributes["deployment"], resource.attributes["k8s.daemonset.name"]) where datapoint.attributes["deployment"] == nil
              - replace_pattern(datapoint.attributes["deployment"], "-[a-f0-9]+$", "")
              - set(datapoint.attributes["phase"], resource.attributes["k8s.pod.phase"])

        log_statements:
          - context: log
            statements:
              - set(severity_text, attributes["level"]) where attributes["level"] != nil
              - set(severity_text, attributes["severity"]) where attributes["severity"] != nil

              - set(severity_number, SEVERITY_NUMBER_INFO) where severity_text == "info"
              - set(severity_number, SEVERITY_NUMBER_WARN) where severity_text == "warn" or severity_text == "warning"
              - set(severity_number, SEVERITY_NUMBER_ERROR) where severity_text == "error"
              - set(severity_number, SEVERITY_NUMBER_DEBUG) where severity_text == "debug"

              - set(body, attributes["msg"]) where attributes["msg"] != nil

              - set(trace_id, attributes["trace_id"]) where attributes["trace_id"] != nil
              - set(span_id, attributes["span_id"]) where attributes["span_id"] != nil

              - set(attributes["trace_id"], nil)
              - set(attributes["span_id"], nil)

      attributes/cleanup:
        actions:
          - key: log.file.path
            action: delete
          - key: logtag
            action: delete

    exporters:
      otlphttp/metrics:
        endpoint: http://127.0.0.1:9090/api/v1/otlp
        tls:
          insecure: true
        sending_queue:
          queue_size: 10000
          
       #prometheusremotewrite:
       # endpoint: http://127.0.0.1:9090/api/v1/write
       # tls:
       #   insecure: true
       # timeout: 30s
       # remote_write_queue:
       #   enabled: true    
       #   num_consumers: 10
       #   queue_size: 10000

      otlphttp/traces:
        endpoint: http://127.0.0.1:4418
        tls:
          insecure: true

      otlphttp/logs:
        endpoint: http://127.0.0.1:3100/otlp
        tls:
          insecure: true

      otlp/profiles:
        endpoint: 127.0.0.1:4040
        tls:
          insecure: true

    service:
      extensions: [health_check]
      pipelines:
        metrics:
          receivers: [
            otlp, 
            kubeletstats, 
            prometheus/self, 
            prometheus/ksm, 
            postgresql, 
            k8s_cluster,
            prometheus/ingress
          ]
          
          # include transform so metric normalization rules are applied
          processors: [memory_limiter, k8sattributes, transform, batch]
          # exporters: [otlphttp/metrics, prometheusremotewrite]
          exporters: [otlphttp/metrics]

        traces:
          receivers: [otlp]
          processors: [memory_limiter, k8sattributes, batch]
          exporters: [otlphttp/traces]

        logs:
          receivers: [otlp, filelog]
          # note: removed 'cri_parser' from processors list; filelog operators handle CRI parsing
          processors: [memory_limiter, k8sattributes, transform, batch, attributes/cleanup]
          exporters: [otlphttp/logs]

        profiles:
          receivers: [otlp]
          exporters: [otlp/profiles]
